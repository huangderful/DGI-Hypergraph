{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 iteration\n",
      "2 iteration\n",
      "3 iteration\n",
      "4 iteration\n",
      "5 iteration\n",
      "6 iteration\n",
      "7 iteration\n",
      "8 iteration\n",
      "9 iteration\n",
      "10 iteration\n",
      "Top Genes by Importance:\n",
      "Gene 85: 0.027567\n",
      "Gene 0: 0.013777\n",
      "Gene 97: 0.013641\n",
      "Gene 189: 0.009792\n",
      "Gene 47: 0.009143\n",
      "Gene 200: 0.003215\n",
      "Gene 17: 0.002779\n",
      "Gene 528: 0.002384\n",
      "Gene 162: 0.002104\n",
      "Gene 184: 0.001750\n",
      "\n",
      "Distance per Iteration:\n",
      "[0.26320896710474495, 0.09055028722027039, 0.026738994035294218, 0.007051998697644948, 0.0019876219121969722, 0.0007312516986020385, 0.000302037993200335, 0.00013486144865043512, 6.167794887390732e-05, 2.8557755697946214e-05]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from scipy.sparse import load_npz\n",
    "\n",
    "# Load matrices\n",
    "# binary_matrix = load_npz(\"../../Data/hypergraphs/DGIDB_HumanNet/human/undirected/bipolar/hypergraph_incidence_matrix_binary.npz\")\n",
    "# weighted_matrix = load_npz(\"../../Data/hypergraphs/DGIDB_HumanNet/human/undirected/bipolar/hypergraph_incidence_matrix_weighted.npz\")\n",
    "binary_matrix = load_npz(\"../../Data/hypergraphs/DGIDB_HumanNet/neighbor/bipolar_k=10_h=1/hypergraph_incidence_matrix_binary.npz\")\n",
    "weighted_matrix = load_npz(\"../../Data/hypergraphs/DGIDB_HumanNet/neighbor/bipolar_k=10_h=1/hypergraph_incidence_matrix_weighted.npz\")\n",
    "# Parameters\n",
    "restart_prob = 0.2  # Restart probability (theta)\n",
    "num_iterations = 10  # Number of iterations\n",
    "num_genes = binary_matrix.shape[0]  # Number of genes\n",
    "num_drugs = binary_matrix.shape[1]  # Number of drugs\n",
    "\n",
    "# Initialize probability vectors\n",
    "v0 = np.ones(num_genes) / num_genes  # Initial uniform probability\n",
    "teleport = np.ones(num_genes) / num_genes  # Restart probability vector\n",
    "\n",
    "def get_hyper_randomwalk(binary_matrix, weighted_matrix, restart_prob, num_iterations):\n",
    "    \"\"\"Performs a hypergraph-based random walk with restart with proper normalization.\"\"\"\n",
    "    vi = v0.copy()  # Start with uniform probability\n",
    "    distance_list = []\n",
    "\n",
    "    for k in range(num_iterations):\n",
    "        print(f\"{k+1} iteration\")\n",
    "\n",
    "        # Store previous probability vector\n",
    "        vj = vi.copy()\n",
    "\n",
    "        # Initialize new probability vector\n",
    "        vi_new = np.zeros(num_genes)\n",
    "\n",
    "        for gene in range(num_genes):\n",
    "            # Find drugs (hyperedges) connected to the current gene\n",
    "            connected_drugs = binary_matrix[gene, :].nonzero()[1]  # Nonzero columns\n",
    "\n",
    "            if len(connected_drugs) == 0:\n",
    "                continue  # Skip if no drugs are found\n",
    "\n",
    "            # Collect probabilities from neighbors\n",
    "            prob_sum = 0\n",
    "            for drug in connected_drugs:\n",
    "                # Find genes connected to the selected drug (via weights)\n",
    "                connected_genes = weighted_matrix[:, drug].toarray().flatten()\n",
    "                neighbor_genes = np.where(connected_genes > 0)[0]  # Get genes with nonzero weight\n",
    "\n",
    "                if len(neighbor_genes) == 0:\n",
    "                    continue\n",
    "\n",
    "                # Normalize weights\n",
    "                weights = connected_genes[neighbor_genes]\n",
    "                weight_sum = np.sum(weights)\n",
    "                if weight_sum > 0:\n",
    "                    weights /= weight_sum  # Normalize to sum to 1\n",
    "\n",
    "                # Transition probability contribution\n",
    "                prob_sum += np.sum(weights * vj[neighbor_genes])  \n",
    "\n",
    "            vi_new[gene] = prob_sum  # Update probability for the gene\n",
    "\n",
    "        # Normalize vi_new to avoid overflow\n",
    "        vi_new /= np.sum(vi_new) if np.sum(vi_new) > 0 else 1\n",
    "\n",
    "        # Apply restart probability\n",
    "        vi = restart_prob * vi_new + (1 - restart_prob) * teleport\n",
    "\n",
    "        # Calculate distance\n",
    "        distance = np.sum(np.abs(vj - vi))\n",
    "        distance_list.append(distance)\n",
    "\n",
    "    # Sort importance scores in descending order\n",
    "    importance_scores = np.argsort(vi)[::-1]\n",
    "    importance_values = vi[importance_scores]\n",
    "\n",
    "    # Return importance scores and distance values\n",
    "    return {\"Importance\": list(zip(importance_scores, importance_values)), \"Distance\": distance_list}\n",
    "\n",
    "# Run the random walk\n",
    "result = get_hyper_randomwalk(binary_matrix, weighted_matrix, restart_prob, num_iterations)\n",
    "\n",
    "# Print results\n",
    "print(\"Top Genes by Importance:\")\n",
    "for gene, score in result[\"Importance\"][:10]:\n",
    "    print(f\"Gene {gene}: {score:.6f}\")\n",
    "\n",
    "print(\"\\nDistance per Iteration:\")\n",
    "print(result[\"Distance\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRACEROUTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from scipy.sparse import load_npz\n",
    "\n",
    "# Load matrices\n",
    "binary_matrix = load_npz(\"../../Data/hypergraphs/DGIDB_HumanNet/human/undirected/bipolar/hypergraph_incidence_matrix_binary.npz\")\n",
    "weighted_matrix = load_npz(\"../../Data/hypergraphs/DGIDB_HumanNet/human/undirected/bipolar/hypergraph_incidence_matrix_weighted.npz\")\n",
    "\n",
    "# Parameters\n",
    "restart_prob = 0.2  # Restart probability (theta)\n",
    "num_iterations = 10  # Number of iterations\n",
    "num_genes = binary_matrix.shape[0]  # Number of genes\n",
    "num_drugs = binary_matrix.shape[1]  # Number of drugs\n",
    "\n",
    "# Initialize probability vectors\n",
    "v0 = np.ones(num_genes) / num_genes  # Initial uniform probability for genes\n",
    "teleport = np.ones(num_genes) / num_genes  # Restart probability vector\n",
    "\n",
    "# Initialize importance vector for drugs\n",
    "\n",
    "def get_hyperedge_importance(binary_matrix, weighted_matrix, restart_prob, num_iterations):\n",
    "    \"\"\"Performs a hypergraph-based random walk with restart and calculates edge importance.\"\"\"\n",
    "    vi = v0.copy()  # Start with uniform probability for genes\n",
    "    distance_list = []\n",
    "    drug_importance = np.zeros(num_drugs)  # To accumulate importance for drugs\n",
    "    for k in range(num_iterations):\n",
    "        print(f\"{k+1} iteration\")\n",
    "\n",
    "        # Store previous probability vector\n",
    "        vj = vi.copy()\n",
    "\n",
    "        # Initialize new probability vectors\n",
    "        vi_new = np.zeros(num_genes)\n",
    "        drug_prob = np.zeros(num_drugs)  # To accumulate probability for drugs\n",
    "\n",
    "        for gene in range(num_genes):\n",
    "            # Find drugs (hyperedges) connected to the current gene\n",
    "            connected_drugs = binary_matrix[gene, :].nonzero()[1]  # Nonzero columns\n",
    "\n",
    "            if len(connected_drugs) == 0:\n",
    "                continue  # Skip if no drugs are found\n",
    "\n",
    "            # Collect probabilities from neighbors\n",
    "            for drug in connected_drugs:\n",
    "                # Find genes connected to the selected drug (via weights)\n",
    "                connected_genes = weighted_matrix[:, drug].toarray().flatten()\n",
    "                neighbor_genes = np.where(connected_genes > 0)[0]  # Get genes with nonzero weight\n",
    "\n",
    "                if len(neighbor_genes) == 0:\n",
    "                    continue\n",
    "\n",
    "                # Normalize weights\n",
    "                weights = connected_genes[neighbor_genes]\n",
    "                weight_sum = np.sum(weights)\n",
    "                if weight_sum > 0:\n",
    "                    weights /= weight_sum  # Normalize to sum to 1\n",
    "\n",
    "                # Transition probability contribution to drug\n",
    "                prob_contribution = np.sum(weights * vj[neighbor_genes])\n",
    "                drug_prob[drug] += prob_contribution  # Accumulate for the drug\n",
    "\n",
    "        # Normalize drug probabilities\n",
    "        drug_prob /= np.sum(drug_prob) if np.sum(drug_prob) > 0 else 1\n",
    "        drug_importance += drug_prob  # Accumulate overall importance\n",
    "        # Apply restart probability to drug\n",
    "        vi_new = binary_matrix @ drug_prob  # Transition back to gene space\n",
    "\n",
    "        # Normalize vi_new to avoid overflow\n",
    "        vi_new /= np.sum(vi_new) if np.sum(vi_new) > 0 else 1\n",
    "\n",
    "        # Apply restart probability to genes\n",
    "        vi = restart_prob * vi_new + (1 - restart_prob) * teleport\n",
    "\n",
    "        # Calculate distance\n",
    "        distance = np.sum(np.abs(vj - vi))\n",
    "        distance_list.append(distance)\n",
    "\n",
    "    # Sort drug importance scores in descending order\n",
    "    importance_scores = np.argsort(drug_importance)[::-1]\n",
    "    importance_values = drug_importance[importance_scores]\n",
    "\n",
    "    # Return importance scores and distance values\n",
    "    return {\"Importance\": list(zip(importance_scores, importance_values)), \"Distance\": distance_list}\n",
    "\n",
    "# Run the random walk to calculate edge importance\n",
    "result = get_hyperedge_importance(binary_matrix, weighted_matrix, restart_prob, num_iterations)\n",
    "\n",
    "# Print results\n",
    "print(\"Top Drugs by Importance:\")\n",
    "for drug, score in result[\"Importance\"][:10]:\n",
    "    print(f\"Drug {drug}: {score:.6f}\")\n",
    "\n",
    "print(\"\\nDistance per Iteration:\")\n",
    "print(result[\"Distance\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load the JSON data from the file\n",
    "with open('../../Data/hypergraphs/DGIDB_HumanNet/human/undirected/bipolar/gene_to_index.json', 'r') as file:\n",
    "    gene_to_index = json.load(file)\n",
    "\n",
    "# Invert the dictionary to map indices back to genes\n",
    "index_to_gene = {v: k for k, v in gene_to_index.items()}\n",
    "\n",
    "def get_gene_by_index(index):\n",
    "    return index_to_gene.get(index, \"Index not found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dgidb = pd.read_csv(\"../../Data/DGIDB/converted/human/dgidb_ncbi_v2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         gene_claim_name gene_concept_id gene_name interaction_source_db_name  \\\n",
      "195                   AR        hgnc:644        AR                        DTC   \n",
      "224                   AR        hgnc:644        AR                     ChEMBL   \n",
      "244                   AR        hgnc:644        AR                        DTC   \n",
      "372                   AR        hgnc:644        AR                        DTC   \n",
      "423                   AR        hgnc:644        AR                        DTC   \n",
      "...                  ...             ...       ...                        ...   \n",
      "87807                 AR        hgnc:644        AR                        DTC   \n",
      "87849                 AR        hgnc:644        AR                        DTC   \n",
      "87863                 AR        hgnc:644        AR                        DTC   \n",
      "88142     UNIPROT:P10275        hgnc:644        AR           TdgClinicalTrial   \n",
      "88237  ANDROGEN RECEPTOR        hgnc:644        AR                        TTD   \n",
      "\n",
      "      interaction_source_db_version interaction_type  interaction_score  \\\n",
      "195                          9/2/20              NaN           0.058472   \n",
      "224                              33          agonist           0.116944   \n",
      "244                          9/2/20              NaN           0.007309   \n",
      "372                          9/2/20              NaN           0.058472   \n",
      "423                          9/2/20              NaN           0.058472   \n",
      "...                             ...              ...                ...   \n",
      "87807                        9/2/20              NaN           0.029236   \n",
      "87849                        9/2/20              NaN           0.058472   \n",
      "87863                        9/2/20              NaN           0.014618   \n",
      "88142                        Jan-14              NaN           0.116944   \n",
      "88237                    2020.06.01              NaN           0.146179   \n",
      "\n",
      "          drug_claim_name      drug_concept_id              drug_name  \\\n",
      "195               ALLISAN  chembl:CHEMBL504381                ALLISAN   \n",
      "224    METHANDROSTENOLONE           rxcui:6818     METHANDROSTENOLONE   \n",
      "244               DANAZOL           rxcui:3102                DANAZOL   \n",
      "372          ORBIFLOXACIN         rxcui:995897           ORBIFLOXACIN   \n",
      "423           MESTANOLONE          ncit:C83939            MESTANOLONE   \n",
      "...                   ...                  ...                    ...   \n",
      "87807       OXIGLUTATIONE          ncit:C62624          OXIGLUTATIONE   \n",
      "87849      SULFACARBAMIDE         ncit:C152453         SULFACARBAMIDE   \n",
      "87863        FLUMETHASONE          rxcui:25113  FLUMETHASONE PIVALATE   \n",
      "88142      DROMOSTANOLONE          rxcui:23678         DROMOSTANOLONE   \n",
      "88237             ARN-509        rxcui:1999574            APALUTAMIDE   \n",
      "\n",
      "      approved immunotherapy anti_neoplastic  ncbi_gene_id  \n",
      "195      False         False           False           367  \n",
      "224       True         False           False           367  \n",
      "244       True         False            True           367  \n",
      "372      False         False           False           367  \n",
      "423      False         False           False           367  \n",
      "...        ...           ...             ...           ...  \n",
      "87807     True         False           False           367  \n",
      "87849     True         False           False           367  \n",
      "87863     True         False           False           367  \n",
      "88142     True         False            True           367  \n",
      "88237     True         False            True           367  \n",
      "\n",
      "[1008 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "print(dgidb[(dgidb['ncbi_gene_id']) == 367])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85\n",
      "Gene 1576, Claim Name: CYP3A4 : 0.027567\n",
      "0\n",
      "Gene 1565, Claim Name: CYP2D6 : 0.013777\n",
      "97\n",
      "Gene 1544, Claim Name: CYP1A2 : 0.013641\n",
      "189\n",
      "Gene 1557, Claim Name: CYP2C19 : 0.009792\n",
      "47\n",
      "Gene 1559, Claim Name: CYP2C9 : 0.009143\n",
      "200\n",
      "Gene 3028, Claim Name: HSD17B10 : 0.003215\n",
      "17\n",
      "Gene 10919, Claim Name: EHMT2 : 0.002779\n",
      "528\n",
      "Gene 216, Claim Name: ALDH1A1 : 0.002384\n",
      "162\n",
      "Gene 367, Claim Name: AR : 0.002104\n",
      "184\n",
      "Gene 4780, Claim Name: NFE2L2 : 0.001750\n"
     ]
    }
   ],
   "source": [
    "# Function to get the gene_claim_name from ncbi_gene_id\n",
    "def get_gene_claim_name(ncbi_gene_id):\n",
    "    ncbi_gene_id = int(ncbi_gene_id)\n",
    "    # result = dgidb[dgidb['ncbi_gene_id'] == ncbi_gene_id]\n",
    "    result = dgidb[(dgidb['ncbi_gene_id']) == ncbi_gene_id]\n",
    "    if not result.empty:\n",
    "        return result['gene_name'].values[0]\n",
    "    else:\n",
    "        return \"Gene name not found\"\n",
    "for gene, score in result[\"Importance\"][:10]:\n",
    "    print(gene)\n",
    "    ncbi_gene = get_gene_by_index(gene)\n",
    "    claim_name = get_gene_claim_name(ncbi_gene)\n",
    "    print(f\"Gene {ncbi_gene}, Claim Name: {claim_name} : {score:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top genes by importance have been saved to 'importance_scores.tsv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'result' is a dictionary with \"Importance\" as a key containing a list of tuples (gene, score)\n",
    "top_genes = result[\"Importance\"]\n",
    "\n",
    "# Create a DataFrame from the top genes\n",
    "df_top_genes = pd.DataFrame(top_genes, columns=['Gene', 'Score'])\n",
    "\n",
    "# Save the DataFrame to a TSV file\n",
    "df_top_genes.to_csv('importance_scores.tsv', sep='\\t', index=False)\n",
    "\n",
    "print(\"Top genes by importance have been saved to 'importance_scores.tsv'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datatestingvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
